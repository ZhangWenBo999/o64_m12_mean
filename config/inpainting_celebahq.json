{
    "name": "inpainting_celebahq", // experiments name
    "gpu_ids": [0], // gpu ids list, default is single 0
    "seed" : -1, // random seed, seed <0 represents randomization not used 
    "finetune_norm": false, // find the parameters to optimize

    "path": { //set every part file path
        "base_dir": "experiments", // base path for all log except resume_state
        "code": "code", // code backup
        "tb_logger": "tb_logger", // path of tensorboard logger
        "results": "results",
        "checkpoint": "checkpoint",
        "resume_state": "/kaggle/input/o64-m12-234/234" 
        // "resume_state": null // ex: 100, loading .state  and .pth from given epoch and iteration
    },

    "datasets": { // train or test
        "train": { 
            "which_dataset": {  // import designated dataset using arguments 
                "name": ["data.dataset", "InpaintDataset"], // import Dataset() class / function(not recommend) from data.dataset.py (default is [data.dataset.py])
                "args":{ // arguments to initialize dataset
                    "data_root": "/kaggle/working/o64_m12_mean/datasets/celebahq/flist/train_64_28000.flist",
                    "data_len": -1,
                    "mask_config": {
                        "mask_mode": "hybrid",
                        "phase": "train",
                        "m12_mode": "mask_generation/lama_generation/random_medium_64.yaml"
                    }
                } 
            },
            "dataloader":{
                "validation_split": 4, // percent or number
                "args":{ // arguments to initialize train_dataloader
                    "batch_size": 5, // batch size in each gpu
                    "num_workers": 4,
                    "shuffle": true,
                    "pin_memory": true,
                    "drop_last": true
                },
                "val_args":{ // arguments to initialize valid_dataloader, will overwrite the parameters in train_dataloader
                    "batch_size": 2, // batch size in each gpu
                    "num_workers": 4,
                    "shuffle": false,
                    "pin_memory": true,
                    "drop_last": true
                }
            }
        },
        "test": { 
            "which_dataset": {
                "name": "InpaintDataset", // import Dataset() class / function(not recommend) from default file
                "args":{
                    "data_root": "/kaggle/working/o64_m12_mean/datasets/celebahq/flist/test_64_2000.flist",
                    "mask_config": {
                        "mask_mode": "center",
                        "phase": "test"
                    }
                }
            },
            "dataloader":{
                "args":{
                    "batch_size": 4,
                    "num_workers": 4,
                    "pin_memory": true
                }
            }
        }
    },

    "model": { // networks/metrics/losses/optimizers/lr_schedulers is a list and model is a dict
        "which_model": { // import designated  model(trainer) using arguments 
            "name": ["models.model", "Palette"], // import Model() class / function(not recommend) from models.model.py (default is [models.model.py])
            "args": {
                "sample_num": 8, // process of each image
                "task": "inpainting",
                "ema_scheduler": {
                    "ema_start": 1,
                    "ema_iter": 1,
                    "ema_decay": 0.9999
                },
                "optimizers": [
                    { "lr": 5e-5, "weight_decay": 0}
                ]
            }
        }, 
        "which_networks": [ // import designated list of networks using arguments
            {
                "name": ["models.network", "Network"], // import Network() class / function(not recommend) from default file (default is [models/network.py]) 
                "args": { // arguments to initialize network
                    "init_type": "kaiming", // method can be [normal | xavier| xavier_uniform | kaiming | orthogonal], default is kaiming
                    "module_name": "guided_diffusion", // sr3 | guided_diffusion
                    "unet": {
                        "in_channel": 6,
                        "out_channel": 3,
                        "inner_channel": 64,
                        "channel_mults": [
                            1,
                            2,
                            4,
                            8
                        ],
                        "attn_res": [
                            // 32,
                            16
                            // 8
                        ],
                        "num_head_channels": 32,
                        "res_blocks": 2,
                        "dropout": 0.2,
                        "image_size": 64
                    },
                    "beta_schedule": {
                        "train": {
                            "schedule": "linear",
                            "n_timestep": 2000,
                            // "n_timestep": 10, // debug
                            "linear_start": 1e-6,
                            "linear_end": 0.01
                        },
                        "test": {
                            "schedule": "linear",
                            "n_timestep": 1000,
                            "linear_start": 1e-4,
                            "linear_end": 0.09
                        }
                    }
                }
            }
        ],
        "which_losses": [ // import designated list of losses without arguments
            "mse_loss" // import mse_loss() function/class from default file (default is [models/losses.py]), equivalent to { "name": "mse_loss", "args":{}}
        ],
        "which_metrics": [ // import designated list of metrics without arguments
            "mae" // import mae() function/class from default file (default is [models/metrics.py]), equivalent to { "name": "mae", "args":{}}
        ]
    },

    "train": { // arguments for basic training
        "n_epoch": 272, // max epochs, not limited now
        "n_iter": 1e8, // max interations
        "val_epoch": 1, // valdation every specified number of epochs
        "save_checkpoint_epoch": 10,
        "log_iter": 1e3, // log every specified number of iterations
        "tensorboard" : false, // tensorboardX enable
        "min_val_mae_loss": 0.038145579397678375,
        "min_val_flag": false,
        "train_previous": [0.10403781415837876, 0.02264183249709767, 0.019056988469094593, 0.01544443919507912, 0.013803063085715063, 0.014173557836661554, 0.013323458932420058, 0.012698838700860495, 0.01263985975813355, 0.012118863552506704, 0.011838315253818477, 0.011538815611537363, 0.011382780708631123, 0.011600517413702114, 0.011458274261185675, 0.01138290097182469, 0.010868881892740006, 0.011145410475051683, 0.010452476018438092, 0.010968954570619336, 0.010496244799011904, 0.01093931497452865, 0.010802543392140802, 0.010234034309618166, 0.01017629184419659, 0.010072139718148458, 0.010279708656182433, 0.010022786699969003, 0.009933171173353815, 0.009743140481866483, 0.010528671492909923, 0.009930368119750566, 0.010663742253800223, 0.010268582696553941, 0.010154010832436175, 0.00990212036918221, 0.009951634869460038, 0.009989012337792294, 0.009638939142086562, 0.009578946441759793, 0.009914386961574616, 0.009444080350956528, 0.009740831592863689, 0.009255817592677337, 0.01006607506417501, 0.009457316888190426, 0.009377697197681573, 0.00988336090212928, 0.009686267123338185, 0.00959374727660422, 0.009474189154353283, 0.009294395001580634, 0.009298313903605498, 0.009787126817683471, 0.0092478712378138, 0.009417757742170766, 0.009708304065423471, 0.0095049763875623, 0.009491986988862316, 0.009463229911526982, 0.009146883445233034, 0.0090125093943129, 0.009300132462223198, 0.00923090123353582, 0.009378985702088246, 0.009153604281880896, 0.009537525373024507, 0.00912004901428329, 0.009335994382589264, 0.009167978948310843, 0.008867692296650137, 0.009316659259581188, 0.008734832592137575, 0.0091213997941261, 0.009395037781905334, 0.008947310067985232, 0.009389449673328994, 0.00896348462054152, 0.008831153937778663, 0.00885186301367369, 0.008654454717307825, 0.008885284768714967, 0.008870814749871529, 0.00867422902748263, 0.00883652512184954, 0.009073531915485752, 0.008595933916865734, 0.008633154773049104, 0.008669949647702383, 0.008811883963264586, 0.008724000059648204, 0.009059151314346888, 0.008506630418745716, 0.008725348956249318, 0.008679995248188303, 0.008765531859815183, 0.00865335765148125, 0.008417156030496907, 0.008577432933476434, 0.008637951126209234, 0.008638025492436205, 0.008590754861609987, 0.008756588501822043, 0.008817750779023206, 0.008651273758173737, 0.00849331254866332, 0.0084825115349938, 0.008872926244025865, 0.008787041317956915, 0.008155041078402222, 0.00887937409179756, 0.008694583695211122, 0.008453483349455813, 0.008602166160999934, 0.008412960606272548, 0.008038574005953203, 0.008615287983693728, 0.008579758854827733, 0.008247715545584365, 0.008679335505869449, 0.008591533240038947, 0.008077251018134515, 0.008401591188998666, 0.00861569890205668, 0.00830591499042612, 0.008288603650054736, 0.008380038072152025, 0.008233877346728168, 0.008221576973096337, 0.00856722092122066, 0.008139797440015726, 0.008749590176425437, 0.008553333703516108, 0.008459202215822649, 0.008235722302095051, 0.008212484527224631, 0.008554987457726801, 0.008135172906505, 0.00886314790639122, 0.008358066674656578, 0.008099469408694953, 0.008227751686767265, 0.008279287032149873, 0.008076927702703497, 0.008207111927800935, 0.00832727432263207, 0.008217691643282123, 0.008290621853247578, 0.008198857854045762, 0.007952127007535609, 0.008261298204138862, 0.008143737452715856, 0.008500095231024853, 0.008732086620659123, 0.008447265043388342, 0.00811977078956815, 0.008550992497579957, 0.0085864147142029, 0.008306247915792592, 0.008589881862267695, 0.008374248658028114, 0.008233580163924727, 0.008565324743073156, 0.008278648577985775, 0.008248433033178935, 0.008280539681839278, 0.008061913897455527, 0.00808850825426057, 0.00857781972347494, 0.008258554191616222, 0.008212555044943037, 0.008380529067002249, 0.008387289654700926, 0.008373671548639675, 0.008181324109858435, 0.008345917405938763, 0.00847160808118968, 0.00855243870024478, 0.008727537100730612, 0.007612000818649828, 0.007974531495149305, 0.007902484555628149, 0.008356083722865773, 0.008051547635835647, 0.008297697533151306, 0.00856347868601445, 0.008380106724929075, 0.00798632368436777, 0.007975450524191357, 0.008154583536305337, 0.008012074849625662, 0.008521052033947754, 0.007823655706257789, 0.007794694810522449, 0.008103980962295733, 0.00799098914835723, 0.008239728766928411, 0.008299280541124896, 0.008234762945638826, 0.008189079758925532, 0.007810661865825993, 0.0075871561841525945, 0.008170181084726245, 0.00784567614659481, 0.00865609776242425, 0.008284012590778433, 0.008018792094644931, 0.008246105791830997, 0.008003143750780437, 0.0080275574422282, 0.00802437230071271, 0.007878476699846983, 0.008073525172049746, 0.00781791762511614, 0.008019240422810832, 0.008188886970541537, 0.008170970813577254, 0.008040382144249354, 0.00820642707490966, 0.007998071280204978, 0.008103223585310118, 0.007978619932686032, 0.008015704823113057, 0.007891096573035938, 0.007973575101469075, 0.008361084147637416, 0.008227405742782613, 0.00762204701202334, 0.008033601671440632, 0.007855144931475903, 0.008251571678434292, 0.008463531992389969, 0.008024508320688888, 0.00794216210251983],
        "eval_previous": [0.11677283048629761, 0.07219347357749939, 0.06575586646795273, 0.0631236881017685, 0.1201009452342987, 0.0625632256269455, 0.06886368989944458, 0.0802500769495964, 0.08913181722164154, 0.08210591226816177, 0.06490623205900192, 0.06688442081212997, 0.05421341955661774, 0.07010725885629654, 0.06271097809076309, 0.05996368080377579, 0.055150941014289856, 0.06483644247055054, 0.08055402338504791, 0.06180157884955406, 0.05985870212316513, 0.053317319601774216, 0.06103047356009483, 0.055121369659900665, 0.047062285244464874, 0.07831493765115738, 0.05392102152109146, 0.05359278991818428, 0.055178940296173096, 0.05321580171585083, 0.06575337052345276, 0.04767325147986412, 0.05715653672814369, 0.047226957976818085, 0.05495753884315491, 0.052016712725162506, 0.05076838284730911, 0.04994731396436691, 0.05890020728111267, 0.05011562258005142, 0.05605834722518921, 0.04131469130516052, 0.04604600369930267, 0.055216290056705475, 0.04792707413434982, 0.06678085029125214, 0.047525569796562195, 0.0472998172044754, 0.05540955811738968, 0.052687328308820724, 0.03956317901611328, 0.06389158964157104, 0.05694849416613579, 0.0515809990465641, 0.052481621503829956, 0.051975417882204056, 0.056964974850416183, 0.054523348808288574, 0.047855816781520844, 0.046348802745342255, 0.050456076860427856, 0.04854883998632431, 0.050141409039497375, 0.04928534850478172, 0.06219206750392914, 0.05299103260040283, 0.05499797314405441, 0.046860139816999435, 0.047563888132572174, 0.049262285232543945, 0.06084972620010376, 0.05876436084508896, 0.047167398035526276, 0.05155312269926071, 0.050812892615795135, 0.044770922511816025, 0.05597391352057457, 0.04296346381306648, 0.04731574282050133, 0.04781658202409744, 0.05701856315135956, 0.043362848460674286, 0.054677389562129974, 0.052132610231637955, 0.05334341526031494, 0.04553591087460518, 0.050996724516153336, 0.04625431075692177, 0.04781263321638107, 0.04101511090993881, 0.04523409903049469, 0.048845402896404266, 0.05397092178463936, 0.046781640499830246, 0.04641248285770416, 0.05343757942318916, 0.04373340308666229, 0.04265350103378296, 0.04816660284996033, 0.051938265562057495, 0.039101533591747284, 0.043364740908145905, 0.04931052029132843, 0.04887840896844864, 0.041385456919670105, 0.050248488783836365, 0.04861003905534744, 0.04954255372285843, 0.042268410325050354, 0.04598619043827057, 0.04877704754471779, 0.04644567891955376, 0.0555487796664238, 0.04521159082651138, 0.04784895107150078, 0.04821176081895828, 0.047210805118083954, 0.04652808979153633, 0.04751516878604889, 0.055843111127614975, 0.049767009913921356, 0.04457126185297966, 0.05100809410214424, 0.04125123471021652, 0.04773266613483429, 0.04595986753702164, 0.04694266617298126, 0.04757663607597351, 0.040875256061553955, 0.043976955115795135, 0.04500148445367813, 0.04495766758918762, 0.04114135354757309, 0.043913841247558594, 0.04896783083677292, 0.04233768954873085, 0.04371113330125809, 0.043757759034633636, 0.04183323308825493, 0.04092217981815338, 0.04456927627325058, 0.042797017842531204, 0.05202082544565201, 0.046646036207675934, 0.04430757835507393, 0.0466732457280159, 0.046089619398117065, 0.04456734657287598, 0.06224919855594635, 0.04609294608235359, 0.043889135122299194, 0.044318974018096924, 0.04244410991668701, 0.04542761668562889, 0.0512361004948616, 0.043048225343227386, 0.04485828056931496, 0.0460556335747242, 0.04115128517150879, 0.04296153038740158, 0.04194135218858719, 0.046867284923791885, 0.039902426302433014, 0.054148703813552856, 0.0492047481238842, 0.03953249752521515, 0.04394140839576721, 0.0437610000371933, 0.04797597974538803, 0.041568636894226074, 0.045698247849941254, 0.046001069247722626, 0.045361921191215515, 0.05016256868839264, 0.04133357107639313, 0.04978051036596298, 0.05027355998754501, 0.04039160907268524, 0.04670850932598114, 0.04400013014674187, 0.04338402301073074, 0.04971088841557503, 0.05578002333641052, 0.044822581112384796, 0.04665575176477432, 0.042100802063941956, 0.040997691452503204, 0.04530952125787735, 0.04384934902191162, 0.04866926744580269, 0.04844793677330017, 0.04366043582558632, 0.04251477122306824, 0.04348180443048477, 0.04779406636953354, 0.043006815016269684, 0.045293137431144714, 0.04352390766143799, 0.04260159283876419, 0.05331067740917206, 0.04338020086288452, 0.042738527059555054, 0.04732126370072365, 0.04509968310594559, 0.041461698710918427, 0.038145579397678375, 0.04649496451020241, 0.044933147728443146, 0.046872660517692566, 0.047740936279296875, 0.043914444744586945, 0.03939906880259514, 0.045912839472293854, 0.054150208830833435, 0.04270271956920624, 0.046283867210149765, 0.04504173994064331, 0.04223065823316574, 0.0520806685090065, 0.044408224523067474, 0.046446993947029114, 0.044432803988456726, 0.045311011373996735, 0.04294532537460327, 0.05210201442241669, 0.041178446263074875, 0.04784597083926201, 0.04334302991628647, 0.042233943939208984, 0.04364604875445366, 0.0412810854613781, 0.0485018715262413, 0.045452363789081573, 0.04744971543550491]
    },
    
    "debug": { // arguments in debug mode, which will replace arguments in train
        "val_epoch": 1,
        "save_checkpoint_epoch": 1,
        "log_iter": 2,
        "debug_split": 50 // percent or number, change the size of dataloder to debug_split.
    }
}
