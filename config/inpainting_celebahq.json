{
    "name": "inpainting_celebahq", // experiments name
    "gpu_ids": [0], // gpu ids list, default is single 0
    "seed" : -1, // random seed, seed <0 represents randomization not used 
    "finetune_norm": false, // find the parameters to optimize

    "path": { //set every part file path
        "base_dir": "experiments", // base path for all log except resume_state
        "code": "code", // code backup
        "tb_logger": "tb_logger", // path of tensorboard logger
        "results": "results",
        "checkpoint": "checkpoint",
        "resume_state": "/kaggle/input/o64-m12-39/39" 
        // "resume_state": null // ex: 100, loading .state  and .pth from given epoch and iteration
    },

    "datasets": { // train or test
        "train": { 
            "which_dataset": {  // import designated dataset using arguments 
                "name": ["data.dataset", "InpaintDataset"], // import Dataset() class / function(not recommend) from data.dataset.py (default is [data.dataset.py])
                "args":{ // arguments to initialize dataset
                    "data_root": "/kaggle/working/o64_m12_mean/datasets/celebahq/flist/train_64_28000.flist",
                    "data_len": -1,
                    "mask_config": {
                        "mask_mode": "hybrid",
                        "phase": "train",
                        "m12_mode": "mask_generation/lama_generation/random_medium_64.yaml"
                    }
                } 
            },
            "dataloader":{
                "validation_split": 4, // percent or number
                "args":{ // arguments to initialize train_dataloader
                    "batch_size": 5, // batch size in each gpu
                    "num_workers": 4,
                    "shuffle": true,
                    "pin_memory": true,
                    "drop_last": true
                },
                "val_args":{ // arguments to initialize valid_dataloader, will overwrite the parameters in train_dataloader
                    "batch_size": 2, // batch size in each gpu
                    "num_workers": 4,
                    "shuffle": false,
                    "pin_memory": true,
                    "drop_last": true
                }
            }
        },
        "test": { 
            "which_dataset": {
                "name": "InpaintDataset", // import Dataset() class / function(not recommend) from default file
                "args":{
                    "data_root": "/kaggle/working/o64_m12_mean/datasets/celebahq/flist/test_64_2000.flist",
                    "mask_config": {
                        "mask_mode": "center",
                        "phase": "test"
                    }
                }
            },
            "dataloader":{
                "args":{
                    "batch_size": 4,
                    "num_workers": 4,
                    "pin_memory": true
                }
            }
        }
    },

    "model": { // networks/metrics/losses/optimizers/lr_schedulers is a list and model is a dict
        "which_model": { // import designated  model(trainer) using arguments 
            "name": ["models.model", "Palette"], // import Model() class / function(not recommend) from models.model.py (default is [models.model.py])
            "args": {
                "sample_num": 8, // process of each image
                "task": "inpainting",
                "ema_scheduler": {
                    "ema_start": 1,
                    "ema_iter": 1,
                    "ema_decay": 0.9999
                },
                "optimizers": [
                    { "lr": 5e-5, "weight_decay": 0}
                ]
            }
        }, 
        "which_networks": [ // import designated list of networks using arguments
            {
                "name": ["models.network", "Network"], // import Network() class / function(not recommend) from default file (default is [models/network.py]) 
                "args": { // arguments to initialize network
                    "init_type": "kaiming", // method can be [normal | xavier| xavier_uniform | kaiming | orthogonal], default is kaiming
                    "module_name": "guided_diffusion", // sr3 | guided_diffusion
                    "unet": {
                        "in_channel": 6,
                        "out_channel": 3,
                        "inner_channel": 64,
                        "channel_mults": [
                            1,
                            2,
                            4,
                            8
                        ],
                        "attn_res": [
                            // 32,
                            16
                            // 8
                        ],
                        "num_head_channels": 32,
                        "res_blocks": 2,
                        "dropout": 0.2,
                        "image_size": 64
                    },
                    "beta_schedule": {
                        "train": {
                            "schedule": "linear",
                            "n_timestep": 2000,
                            // "n_timestep": 10, // debug
                            "linear_start": 1e-6,
                            "linear_end": 0.01
                        },
                        "test": {
                            "schedule": "linear",
                            "n_timestep": 1000,
                            "linear_start": 1e-4,
                            "linear_end": 0.09
                        }
                    }
                }
            }
        ],
        "which_losses": [ // import designated list of losses without arguments
            "mse_loss" // import mse_loss() function/class from default file (default is [models/losses.py]), equivalent to { "name": "mse_loss", "args":{}}
        ],
        "which_metrics": [ // import designated list of metrics without arguments
            "mae" // import mae() function/class from default file (default is [models/metrics.py]), equivalent to { "name": "mae", "args":{}}
        ]
    },

    "train": { // arguments for basic training
        "n_epoch": 78, // max epochs, not limited now
        "n_iter": 1e8, // max interations
        "val_epoch": 1, // valdation every specified number of epochs
        "save_checkpoint_epoch": 10,
        "log_iter": 1e3, // log every specified number of iterations
        "tensorboard" : false, // tensorboardX enable
        "min_val_mae_loss": 0.047062285244464874,
        "min_val_flag": false,
        "train_previous": [0.10403781415837876, 0.02264183249709767, 0.019056988469094593, 0.01544443919507912, 0.013803063085715063, 0.014173557836661554, 0.013323458932420058, 0.012698838700860495, 0.01263985975813355, 0.012118863552506704, 0.011838315253818477, 0.011538815611537363, 0.011382780708631123, 0.011600517413702114, 0.011458274261185675, 0.01138290097182469, 0.010868881892740006, 0.011145410475051683, 0.010452476018438092, 0.010968954570619336, 0.010496244799011904, 0.01093931497452865, 0.010802543392140802, 0.010234034309618166, 0.01017629184419659, 0.010072139718148458, 0.010279708656182433, 0.010022786699969003, 0.009933171173353815, 0.009743140481866483, 0.010528671492909923, 0.009930368119750566, 0.010663742253800223, 0.010268582696553941, 0.010154010832436175, 0.00990212036918221, 0.009951634869460038, 0.009989012337792294, 0.009638939142086562],
        "eval_previous": [0.11677283048629761, 0.07219347357749939, 0.06575586646795273, 0.0631236881017685, 0.1201009452342987, 0.0625632256269455, 0.06886368989944458, 0.0802500769495964, 0.08913181722164154, 0.08210591226816177, 0.06490623205900192, 0.06688442081212997, 0.05421341955661774, 0.07010725885629654, 0.06271097809076309, 0.05996368080377579, 0.055150941014289856, 0.06483644247055054, 0.08055402338504791, 0.06180157884955406, 0.05985870212316513, 0.053317319601774216, 0.06103047356009483, 0.055121369659900665, 0.047062285244464874, 0.07831493765115738, 0.05392102152109146, 0.05359278991818428, 0.055178940296173096, 0.05321580171585083, 0.06575337052345276, 0.04767325147986412, 0.05715653672814369, 0.047226957976818085, 0.05495753884315491, 0.052016712725162506, 0.05076838284730911, 0.04994731396436691, 0.05890020728111267]
    },
    
    "debug": { // arguments in debug mode, which will replace arguments in train
        "val_epoch": 1,
        "save_checkpoint_epoch": 1,
        "log_iter": 2,
        "debug_split": 50 // percent or number, change the size of dataloder to debug_split.
    }
}
